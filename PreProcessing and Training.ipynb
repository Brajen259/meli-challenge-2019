{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anderson93/meli-challenge-2019/blob/master/PreProcessing%20and%20Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6WmQlbIW4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "f3790031-577c-419f-c7fb-ef7e17dfcf1e"
      },
      "source": [
        "!wget https://meli-data-challenge.s3.amazonaws.com/train.csv.gz\n",
        "!wget https://meli-data-challenge.s3.amazonaws.com/test.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-10 18:11:23--  https://meli-data-challenge.s3.amazonaws.com/train.csv.gz\n",
            "Resolving meli-data-challenge.s3.amazonaws.com (meli-data-challenge.s3.amazonaws.com)... 52.216.136.244\n",
            "Connecting to meli-data-challenge.s3.amazonaws.com (meli-data-challenge.s3.amazonaws.com)|52.216.136.244|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 691651384 (660M) [application/x-gzip]\n",
            "Saving to: ‘train.csv.gz’\n",
            "\n",
            "train.csv.gz        100%[===================>] 659.61M  29.4MB/s    in 20s     \n",
            "\n",
            "2019-09-10 18:11:43 (33.1 MB/s) - ‘train.csv.gz’ saved [691651384/691651384]\n",
            "\n",
            "--2019-09-10 18:11:45--  https://meli-data-challenge.s3.amazonaws.com/test.csv\n",
            "Resolving meli-data-challenge.s3.amazonaws.com (meli-data-challenge.s3.amazonaws.com)... 54.231.81.56\n",
            "Connecting to meli-data-challenge.s3.amazonaws.com (meli-data-challenge.s3.amazonaws.com)|54.231.81.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16467436 (16M) [text/csv]\n",
            "Saving to: ‘test.csv’\n",
            "\n",
            "test.csv            100%[===================>]  15.70M  16.7MB/s    in 0.9s    \n",
            "\n",
            "2019-09-10 18:11:47 (16.7 MB/s) - ‘test.csv’ saved [16467436/16467436]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMbShyeeM-6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "b38f8450-7af0-4a45-f19e-7d41d93e638e"
      },
      "source": [
        "!pip install pytorch-transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/b7/d3d18008a67e0b968d1ab93ad444fc05699403fa662f634b2f2c318a508b/pytorch_transformers-1.2.0-py3-none-any.whl (176kB)\n",
            "\r\u001b[K     |█▉                              | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |███▊                            | 20kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 71kB 9.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 81kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 92kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 112kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 122kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 133kB 9.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 143kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 153kB 9.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 163kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 174kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184kB 9.6MB/s \n",
            "\u001b[?25hCollecting regex (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/a6/99eeb5904ab763db87af4bd71d9b1dfdd9792681240657a4c0a599c10a81/regex-2019.08.19.tar.gz (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 35.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.9.224)\n",
            "Collecting sentencepiece (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 53.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.16.5)\n",
            "Collecting sacremoses (from pytorch-transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/24/0b86f494d3a5c7531f6d0c77d39fd8f9d42e651244505d3d737e31db9a4d/sacremoses-0.0.33.tar.gz (802kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 42.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-transformers) (1.1.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-transformers) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.224 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (1.12.224)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-transformers) (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->pytorch-transformers) (0.13.2)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch-transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.224->boto3->pytorch-transformers) (2.5.3)\n",
            "Building wheels for collected packages: regex, sacremoses\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.8.19-cp36-cp36m-linux_x86_64.whl size=609232 sha256=2aac2d2f6bffd61ee6714f9b9ecd94cb8bc532707c974e5fa36db7689ee95d50\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/04/07/b5010fb816721eb3d6dd64ed5cc8111ca23f97fdab8619b5be\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.33-cp36-none-any.whl size=833106 sha256=888b2093acdcabe90ca29f1e40844d4026dbaa286be222f9929c81a9e708e855\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/87/56/e40575cca30d12fee8875d523b8878b7aba866a9f03b2fd983\n",
            "Successfully built regex sacremoses\n",
            "Installing collected packages: regex, sentencepiece, sacremoses, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.2.0 regex-2019.8.19 sacremoses-0.0.33 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0jJyzNlIffT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_n_test = pd.read_csv('train.csv.gz', compression = 'gzip')\n",
        "validation = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HQqabUdCaTp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sep = ' '\n",
        "train_n_test['input'] = pd.Series(map(lambda x: x[0]+sep+x[1].replace(' ',sep), train_n_test[['language','title']].values))\n",
        "\n",
        "label_to_token = {x:i for i,x in enumerate(pd.unique(train_n_test['category']))}\n",
        "token_to_label = {i:x for i,x in enumerate(pd.unique(train_n_test['category']))}\n",
        "train_n_test['label_tokenized'] = train_n_test['category'].apply(lambda x: label_dict[x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K6qzGCrK8cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = train_n_test[train_n_test['label_quality']=='reliable']['input'].values\n",
        "y = train_n_test[train_n_test['label_quality']=='reliable']['label_tokenized'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=420)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7RkAqwaKmQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c6d52c09-a6e5-44e3-b26b-5e28790f3e60"
      },
      "source": [
        "train = pd.DataFrame({0:y_train, 1:X_train})\n",
        "test = pd.DataFrame({0:y_test, 1:X_test})\n",
        "train.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>665</td>\n",
              "      <td>spanish Dvd Portátil V-zon Coby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1385</td>\n",
              "      <td>portuguese Depiladora Luz Pulsada - Mlay Ipl O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>868</td>\n",
              "      <td>spanish Ultrabook Hp Elitebook 840 G1 I5 500gb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>portuguese Tapete Sisal Macio Clean Linhas Dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69</td>\n",
              "      <td>portuguese Leite Neocate Lcp 400g Caixa Com 04...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0                                                  1\n",
              "0   665                    spanish Dvd Portátil V-zon Coby\n",
              "1  1385  portuguese Depiladora Luz Pulsada - Mlay Ipl O...\n",
              "2   868  spanish Ultrabook Hp Elitebook 840 G1 I5 500gb...\n",
              "3    25  portuguese Tapete Sisal Macio Clean Linhas Dia...\n",
              "4    69  portuguese Leite Neocate Lcp 400g Caixa Com 04..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXeGBCOuAjN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "abcb1821-6b8b-4127-adbe-54b405b88b42"
      },
      "source": [
        "train_df = pd.DataFrame({\n",
        "    'id':range(len(train)),\n",
        "    'label':train[0],\n",
        "    'alpha':['a']*train.shape[0],\n",
        "    'text': train[1].replace(r'\\n', ' ', regex=True)\n",
        "})\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>alpha</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>665</td>\n",
              "      <td>a</td>\n",
              "      <td>spanish Dvd Portátil V-zon Coby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1385</td>\n",
              "      <td>a</td>\n",
              "      <td>portuguese Depiladora Luz Pulsada - Mlay Ipl O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>868</td>\n",
              "      <td>a</td>\n",
              "      <td>spanish Ultrabook Hp Elitebook 840 G1 I5 500gb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>a</td>\n",
              "      <td>portuguese Tapete Sisal Macio Clean Linhas Dia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>69</td>\n",
              "      <td>a</td>\n",
              "      <td>portuguese Leite Neocate Lcp 400g Caixa Com 04...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  label alpha                                               text\n",
              "0   0    665     a                    spanish Dvd Portátil V-zon Coby\n",
              "1   1   1385     a  portuguese Depiladora Luz Pulsada - Mlay Ipl O...\n",
              "2   2    868     a  spanish Ultrabook Hp Elitebook 840 G1 I5 500gb...\n",
              "3   3     25     a  portuguese Tapete Sisal Macio Clean Linhas Dia...\n",
              "4   4     69     a  portuguese Leite Neocate Lcp 400g Caixa Com 04..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOe-9cgXM4eQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dev_df = pd.DataFrame({\n",
        "    'id':range(len(test)),\n",
        "    'label':test[0],\n",
        "    'alpha':['a']*test.shape[0],\n",
        "    'text': test[1].replace(r'\\n', ' ', regex=True)\n",
        "})\n",
        "\n",
        "dev_df.head()\n",
        "\n",
        "train_df.to_csv('train.tsv', sep='\\t', index=False, header=False)\n",
        "dev_df.to_csv('dev.tsv', sep='\\t', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl41NukmNwYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "a16b09d6-3c70-4ca7-b4e9-c06703154097"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/ThilinaRajapakse/pytorch-transformers-classification/master/utils.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-10 18:13:24--  https://raw.githubusercontent.com/ThilinaRajapakse/pytorch-transformers-classification/master/utils.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12933 (13K) [text/plain]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "\rutils.py              0%[                    ]       0  --.-KB/s               \rutils.py            100%[===================>]  12.63K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-09-10 18:13:24 (173 MB/s) - ‘utils.py’ saved [12933/12933]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLjSdIWMNGf7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import glob\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import random\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from tqdm import tqdm_notebook, trange\n",
        "\n",
        "\n",
        "from pytorch_transformers import (WEIGHTS_NAME, BertConfig, BertForSequenceClassification, BertTokenizer,\n",
        "                                  XLMConfig, XLMForSequenceClassification, XLMTokenizer, \n",
        "                                  XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer,\n",
        "                                  RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
        "\n",
        "from pytorch_transformers import AdamW, WarmupLinearSchedule\n",
        "\n",
        "from utils import (convert_examples_to_features,\n",
        "                        output_modes, processors)\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoXZ1i0bInBt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {\n",
        "    'data_dir': '/',\n",
        "    'model_type':  'xlm',\n",
        "    'model_name': 'xlm-mlm-tlm-xnli15-1024',\n",
        "    'task_name': 'multiclass',\n",
        "    'output_dir': 'outputs/',\n",
        "    'cache_dir': 'cache/',\n",
        "    'do_train': True,\n",
        "    'do_eval': True,\n",
        "    'fp16': True,\n",
        "    'fp16_opt_level': 'O1',\n",
        "    'max_seq_length': 128,\n",
        "    'output_mode': 'classification',\n",
        "    'train_batch_size': 8,\n",
        "    'eval_batch_size': 8,\n",
        "\n",
        "    'gradient_accumulation_steps': 1,\n",
        "    'num_train_epochs': 1,\n",
        "    'weight_decay': 0,\n",
        "    'learning_rate': 4e-5,\n",
        "    'adam_epsilon': 1e-8,\n",
        "    'warmup_steps': 0,\n",
        "    'max_grad_norm': 1.0,\n",
        "\n",
        "    'logging_steps': 50,\n",
        "    'evaluate_during_training': False,\n",
        "    'save_steps': 2000,\n",
        "    'eval_all_checkpoints': True,\n",
        "\n",
        "    'overwrite_output_dir': False,\n",
        "    'reprocess_input_data': True,\n",
        "    'notes': 'Using MeLi Challenge dataset'\n",
        "}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtiPT9-qPg7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "beff45b1-134f-4a96-b3d9-0cda93eb336d"
      },
      "source": [
        "with open('args.json', 'w') as f:\n",
        "    json.dump(args, f)\n",
        "    \n",
        "if os.path.exists(args['output_dir']) and os.listdir(args['output_dir']) and args['do_train'] and not args['overwrite_output_dir']:\n",
        "    raise ValueError(\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\".format(args['output_dir']))\n",
        "    \n",
        "MODEL_CLASSES = {\n",
        "    'bert': (BertConfig, BertForSequenceClassification, BertTokenizer),\n",
        "    'xlnet': (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer),\n",
        "    'xlm': (XLMConfig, XLMForSequenceClassification, XLMTokenizer),\n",
        "    'roberta': (RobertaConfig, RobertaForSequenceClassification, RobertaTokenizer)\n",
        "}\n",
        "\n",
        "config_class, model_class, tokenizer_class = MODEL_CLASSES[args['model_type']]\n",
        "\n",
        "config = config_class.from_pretrained(args['model_name'], \n",
        "                                      num_labels=len([str(x) for x in token_to_label.keys()]), \n",
        "                                      finetuning_task=args['task_name'])\n",
        "tokenizer = tokenizer_class.from_pretrained(args['model_name'])\n",
        "\n",
        "model = model_class.from_pretrained(args['model_name'])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-tlm-xnli15-1024-config.json from cache at /root/.cache/torch/pytorch_transformers/a4852a980f0b11e78249cdcc71b5d176d87abcbafa83b669949efa2875430f2e.5c9c090b1e1150f496832947811eff8bb318d046786a96e364b8576f7b4660fb\n",
            "INFO:pytorch_transformers.modeling_utils:Model config {\n",
            "  \"asm\": false,\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_index\": 0,\n",
            "  \"causal\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"emb_dim\": 1024,\n",
            "  \"embed_init_std\": 0.02209708691207961,\n",
            "  \"end_n_top\": 5,\n",
            "  \"eos_index\": 1,\n",
            "  \"finetuning_task\": \"multiclass\",\n",
            "  \"gelu_activation\": true,\n",
            "  \"id2lang\": {\n",
            "    \"0\": \"ar\",\n",
            "    \"1\": \"bg\",\n",
            "    \"10\": \"th\",\n",
            "    \"11\": \"tr\",\n",
            "    \"12\": \"ur\",\n",
            "    \"13\": \"vi\",\n",
            "    \"14\": \"zh\",\n",
            "    \"2\": \"de\",\n",
            "    \"3\": \"el\",\n",
            "    \"4\": \"en\",\n",
            "    \"5\": \"es\",\n",
            "    \"6\": \"fr\",\n",
            "    \"7\": \"hi\",\n",
            "    \"8\": \"ru\",\n",
            "    \"9\": \"sw\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder\": true,\n",
            "  \"lang2id\": {\n",
            "    \"ar\": 0,\n",
            "    \"bg\": 1,\n",
            "    \"de\": 2,\n",
            "    \"el\": 3,\n",
            "    \"en\": 4,\n",
            "    \"es\": 5,\n",
            "    \"fr\": 6,\n",
            "    \"hi\": 7,\n",
            "    \"ru\": 8,\n",
            "    \"sw\": 9,\n",
            "    \"th\": 10,\n",
            "    \"tr\": 11,\n",
            "    \"ur\": 12,\n",
            "    \"vi\": 13,\n",
            "    \"zh\": 14\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mask_index\": 5,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_vocab\": 95000,\n",
            "  \"min_count\": 0,\n",
            "  \"n_heads\": 8,\n",
            "  \"n_langs\": 15,\n",
            "  \"n_layers\": 12,\n",
            "  \"n_words\": 95000,\n",
            "  \"num_labels\": 1588,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_index\": 2,\n",
            "  \"pruned_heads\": {},\n",
            "  \"same_enc_dec\": true,\n",
            "  \"share_inout_emb\": true,\n",
            "  \"sinusoidal_embeddings\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"unk_index\": 3,\n",
            "  \"use_lang_emb\": true\n",
            "}\n",
            "\n",
            "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-tlm-xnli15-1024-vocab.json from cache at /root/.cache/torch/pytorch_transformers/98a90bc3685cbbf0c39b0b75bbee0d29ec9c18dd01507c872e1385e8f9a2d62e.99234596be1c0bb1a86f577138f0aedbc1c6daa4255ff975a609f07ca9f5fb4f\n",
            "INFO:pytorch_transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-tlm-xnli15-1024-merges.txt from cache at /root/.cache/torch/pytorch_transformers/2b505d42bfe7bcc200a8bc8fd31873f14ee41eea6f7998da4a5073d38ca16fbd.972e07b26e2b41e5f03918bd0ccf208262a02873efdebd9702803e6bd078d395\n",
            "INFO:pytorch_transformers.modeling_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-tlm-xnli15-1024-config.json from cache at /root/.cache/torch/pytorch_transformers/a4852a980f0b11e78249cdcc71b5d176d87abcbafa83b669949efa2875430f2e.5c9c090b1e1150f496832947811eff8bb318d046786a96e364b8576f7b4660fb\n",
            "INFO:pytorch_transformers.modeling_utils:Model config {\n",
            "  \"asm\": false,\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_index\": 0,\n",
            "  \"causal\": false,\n",
            "  \"dropout\": 0.1,\n",
            "  \"emb_dim\": 1024,\n",
            "  \"embed_init_std\": 0.02209708691207961,\n",
            "  \"end_n_top\": 5,\n",
            "  \"eos_index\": 1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gelu_activation\": true,\n",
            "  \"id2lang\": {\n",
            "    \"0\": \"ar\",\n",
            "    \"1\": \"bg\",\n",
            "    \"10\": \"th\",\n",
            "    \"11\": \"tr\",\n",
            "    \"12\": \"ur\",\n",
            "    \"13\": \"vi\",\n",
            "    \"14\": \"zh\",\n",
            "    \"2\": \"de\",\n",
            "    \"3\": \"el\",\n",
            "    \"4\": \"en\",\n",
            "    \"5\": \"es\",\n",
            "    \"6\": \"fr\",\n",
            "    \"7\": \"hi\",\n",
            "    \"8\": \"ru\",\n",
            "    \"9\": \"sw\"\n",
            "  },\n",
            "  \"init_std\": 0.02,\n",
            "  \"is_encoder\": true,\n",
            "  \"lang2id\": {\n",
            "    \"ar\": 0,\n",
            "    \"bg\": 1,\n",
            "    \"de\": 2,\n",
            "    \"el\": 3,\n",
            "    \"en\": 4,\n",
            "    \"es\": 5,\n",
            "    \"fr\": 6,\n",
            "    \"hi\": 7,\n",
            "    \"ru\": 8,\n",
            "    \"sw\": 9,\n",
            "    \"th\": 10,\n",
            "    \"tr\": 11,\n",
            "    \"ur\": 12,\n",
            "    \"vi\": 13,\n",
            "    \"zh\": 14\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"mask_index\": 5,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_vocab\": 95000,\n",
            "  \"min_count\": 0,\n",
            "  \"n_heads\": 8,\n",
            "  \"n_langs\": 15,\n",
            "  \"n_layers\": 12,\n",
            "  \"n_words\": 95000,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_index\": 2,\n",
            "  \"pruned_heads\": {},\n",
            "  \"same_enc_dec\": true,\n",
            "  \"share_inout_emb\": true,\n",
            "  \"sinusoidal_embeddings\": false,\n",
            "  \"start_n_top\": 5,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torchscript\": false,\n",
            "  \"unk_index\": 3,\n",
            "  \"use_lang_emb\": true\n",
            "}\n",
            "\n",
            "INFO:pytorch_transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/xlm-mlm-tlm-xnli15-1024-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/db42a3f32fc6978768ec810a1483b80063722f4dfb47db2a09865d75efc045f5.ad434134426e93a77f30afdf56867ab0c8977e649dcff440adc6fb2f5f2d35b7\n",
            "INFO:pytorch_transformers.modeling_utils:Weights from pretrained model not used in XLMForSequenceClassification: ['pred_layer.proj.weight', 'pred_layer.proj.bias']\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYJNzYqUPgcL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b94ba6b-a073-4de2-ead9-2e495b9aa2f4"
      },
      "source": [
        "model.to(device);\n",
        "device"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4_gcqlFJbjR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "38495043-61fb-47df-828a-5e3f9fd7129a"
      },
      "source": [
        "task = args['task_name']\n",
        "\n",
        "processor = processors[task]()\n",
        "label_list = processor.get_labels(token_to_label.keys())\n",
        "num_labels = len(label_list)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-159f1f494a58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiClassProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlabel_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_to_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MultiClassProcessor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPX1lN34VLXF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "98eb417b-1e29-4d15-ae30-534dcc4c2a4f"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "args.json  drive\t\t__pycache__  test.csv\t   train.tsv\n",
            "dev.tsv    meli-challenge-2019\tsample_data  train.csv.gz  utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2XtHbAIdL2U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "a03a129b-a53a-41d6-c7fd-55009594c899"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEFyCOgNcUuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp meli-challenge-2019/* drive/My\\ Drive/Projekts/meli-challenge-2019"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0KmtfwqUYgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_cache_examples(task, tokenizer, evaluate=False, undersample_scale_factor=1):\n",
        "    processor = processors[task]()\n",
        "    output_mode = args['output_mode']\n",
        "    \n",
        "    mode = 'dev' if evaluate else 'train'\n",
        "    cached_features_file = os.path.join(args['data_dir'], f\"cached_{mode}_{args['model_name']}_{args['max_seq_length']}_{task}\")\n",
        "    \n",
        "    if os.path.exists(cached_features_file) and not args['reprocess_input_data']:\n",
        "        logger.info(\"Loading features from cached file %s\", cached_features_file)\n",
        "        features = torch.load(cached_features_file)\n",
        "               \n",
        "    else:\n",
        "        logger.info(\"Creating features from dataset file at %s\", args['data_dir'])\n",
        "        label_list = processor.get_labels()\n",
        "        examples = processor.get_dev_examples(args['data_dir']) if evaluate else processor.get_train_examples(args['data_dir'])\n",
        "        print(len(examples))\n",
        "        examples  = [example for example in examples if np.random.rand() < undersample_scale_factor]\n",
        "        print(len(examples))\n",
        "        \n",
        "        features = convert_examples_to_features(examples, label_list, args['max_seq_length'], tokenizer, output_mode,\n",
        "            cls_token_at_end=bool(args['model_type'] in ['xlnet']),            # xlnet has a cls token at the end\n",
        "            cls_token=tokenizer.cls_token,\n",
        "            sep_token=tokenizer.sep_token,\n",
        "            cls_token_segment_id=2 if args['model_type'] in ['xlnet'] else 0,\n",
        "            pad_on_left=bool(args['model_type'] in ['xlnet']),                 # pad on the left for xlnet\n",
        "            pad_token_segment_id=4 if args['model_type'] in ['xlnet'] else 0,\n",
        "            process_count=2)\n",
        "        \n",
        "        logger.info(\"Saving features into cached file %s\", cached_features_file)\n",
        "        torch.save(features, cached_features_file)\n",
        "        \n",
        "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "    if output_mode == \"classification\":\n",
        "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
        "    elif output_mode == \"regression\":\n",
        "        all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.float)\n",
        "\n",
        "    dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "    return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_3qSTIVUYcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQe5fgN_UYac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reE0NXmkUYXz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03KeBXYoUYUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJZEcW43UYEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}